{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvWtKK0f2xrCEf+d/eHeb/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidya100804/AI-ML/blob/main/Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAPBFS2P3XxG",
        "outputId": "567290fa-102c-471c-d833-e5c948ac1d5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txg8RRH6seM3",
        "outputId": "24148b24-bd22-4905-9f6d-aaf3dcf190ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories used: ['eenadu_sports', 'eenadu_national']. Mapping: eenadu_sports -> 0 (Fake), eenadu_national -> 1 (Correct)\n",
            "Training Logistic Regression...\n",
            "  Logistic Regression Accuracy: 0.9733\n",
            "Training Naive Bayes...\n",
            "  Naive Bayes Accuracy: 0.9713\n",
            "Training Random Forest...\n",
            "  Random Forest Accuracy: 0.9738\n",
            "Training Decision Trees...\n",
            "  Decision Trees Accuracy: 0.9388\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:54:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  XGBoost Accuracy: 0.9772\n",
            "Training CatBoost...\n",
            "  CatBoost Accuracy: 0.9699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM...\n",
            "  LSTM Accuracy: 0.9329\n",
            "\n",
            "--- Model Accuracies ---\n",
            "XGBoost: 0.9772\n",
            "Random Forest: 0.9738\n",
            "Logistic Regression: 0.9733\n",
            "Naive Bayes: 0.9713\n",
            "CatBoost: 0.9699\n",
            "Decision Trees: 0.9388\n",
            "LSTM: 0.9329\n",
            "\n",
            "Highest Accurate Technique: XGBoost (0.9772)\n",
            "\n",
            "Prediction complete. Output saved to 'fake_news_predictions.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Conditional Imports for External Libraries ---\n",
        "import xgboost as xgb\n",
        "try:\n",
        "    from catboost import CatBoostClassifier\n",
        "    CATBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    CATBOOST_AVAILABLE = False\n",
        "    print(\"CatBoost not installed. Skipping CatBoost.\")\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "    LSTM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    LSTM_AVAILABLE = False\n",
        "    print(\"TensorFlow/Keras not installed. Skipping LSTM.\")\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "TRAIN_FILE = '/content/telugu_news_dataset.parquet'\n",
        "TEST_FILE = '/content/telugu_news_test.parquet'\n",
        "\n",
        "try:\n",
        "    train_df = pd.read_parquet(TRAIN_FILE)\n",
        "    test_df = pd.read_parquet(TEST_FILE)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}. Ensure the files are accessible.\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Preprocessing and Feature Engineering ---\n",
        "\n",
        "# Define columns (assuming standard structure based on metadata snippets)\n",
        "TEXT_COLS = ['title', 'text']\n",
        "LABEL_COL = 'category'\n",
        "\n",
        "# Fill NA values and combine text\n",
        "for col in TEXT_COLS:\n",
        "    train_df[col] = train_df[col].fillna('')\n",
        "    test_df[col] = test_df[col].fillna('')\n",
        "\n",
        "train_df['combined_text'] = train_df[TEXT_COLS].agg(' '.join, axis=1)\n",
        "test_df['combined_text'] = test_df[TEXT_COLS].agg(' '.join, axis=1)\n",
        "\n",
        "# Text cleaning function (generic for multilingual data)\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text) # Remove punctuation\n",
        "    text = re.sub(r'\\d+', ' ', text)      # Remove numbers\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Replace multiple spaces with single space\n",
        "    return text\n",
        "\n",
        "train_df['combined_text'] = train_df['combined_text'].apply(clean_text)\n",
        "test_df['combined_text'] = test_df['combined_text'].apply(clean_text)\n",
        "\n",
        "# --- 3. Label Encoding for Binary Classification (Fake/Correct) ---\n",
        "\n",
        "# Filter to the two most frequent categories to create a clear binary classification\n",
        "if LABEL_COL not in train_df.columns:\n",
        "    print(f\"Label column '{LABEL_COL}' not found in training data. Cannot proceed with classification.\")\n",
        "    exit()\n",
        "\n",
        "top_categories = train_df[LABEL_COL].value_counts().nlargest(2).index.tolist()\n",
        "\n",
        "if len(top_categories) < 2:\n",
        "    print(\"Insufficient categories for binary classification (Fake/Correct). Please check the 'category' column.\")\n",
        "    exit()\n",
        "\n",
        "# Filter the training data to only include the top 2 categories\n",
        "train_df_filtered = train_df[train_df[LABEL_COL].isin(top_categories)].copy()\n",
        "\n",
        "# Map the categories: First most frequent category -> 0 (Fake), Second most frequent category -> 1 (Correct)\n",
        "category_map = {top_categories[0]: 0, top_categories[1]: 1}\n",
        "train_df_filtered['label'] = train_df_filtered[LABEL_COL].map(category_map)\n",
        "\n",
        "print(f\"Categories used: {top_categories}. Mapping: {top_categories[0]} -> 0 (Fake), {top_categories[1]} -> 1 (Correct)\")\n",
        "\n",
        "X_train_data = train_df_filtered['combined_text']\n",
        "y_train = train_df_filtered['label']\n",
        "\n",
        "# Split the training data for model evaluation\n",
        "X_train, X_val, y_train_split, y_val_split = train_test_split(\n",
        "    X_train_data, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "# --- 4. Feature Extraction: TF-IDF Vectorizer (for ML Models) ---\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf.transform(X_val)\n",
        "X_test_tfidf = tfidf.transform(test_df['combined_text'])\n",
        "\n",
        "# --- 5. Model Training and Evaluation (ML Models) ---\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(solver='liblinear', random_state=42, max_iter=1000),\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    'Decision Trees': DecisionTreeClassifier(random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)\n",
        "}\n",
        "\n",
        "if CATBOOST_AVAILABLE:\n",
        "    models['CatBoost'] = CatBoostClassifier(verbose=0, random_state=42, allow_writing_files=False)\n",
        "\n",
        "accuracies = {}\n",
        "trained_models = {}\n",
        "\n",
        "# Train and evaluate ML models\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train_tfidf, y_train_split)\n",
        "    y_pred = model.predict(X_val_tfidf)\n",
        "    accuracy = accuracy_score(y_val_split, y_pred)\n",
        "    accuracies[name] = accuracy\n",
        "    trained_models[name] = model\n",
        "    print(f\"  {name} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# --- 6. LSTM Model Training and Evaluation (DL Model) ---\n",
        "\n",
        "if LSTM_AVAILABLE:\n",
        "    # Hyperparameters for LSTM\n",
        "    MAX_WORDS = 20000\n",
        "    MAX_SEQUENCE_LENGTH = 150\n",
        "    EMBEDDING_DIM = 128\n",
        "\n",
        "    # Tokenization and Padding\n",
        "    tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<unk>\")\n",
        "    tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "    X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "    X_test_seq = tokenizer.texts_to_sequences(test_df['combined_text'])\n",
        "\n",
        "    X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "    X_val_padded = pad_sequences(X_val_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "    X_test_padded = pad_sequences(X_test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "    # Build LSTM Model\n",
        "    lstm_model = Sequential([\n",
        "        Embedding(MAX_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
        "        Dropout(0.3),\n",
        "        LSTM(128),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nTraining LSTM...\")\n",
        "    # Train the model (using a small number of epochs for speed)\n",
        "    lstm_model.fit(\n",
        "        X_train_padded, np.array(y_train_split),\n",
        "        epochs=4,\n",
        "        batch_size=64,\n",
        "        validation_data=(X_val_padded, np.array(y_val_split)),\n",
        "        verbose=0\n",
        "    )\n",
        "    trained_models['LSTM'] = lstm_model\n",
        "\n",
        "    # Evaluate LSTM\n",
        "    _, lstm_accuracy = lstm_model.evaluate(X_val_padded, np.array(y_val_split), verbose=0)\n",
        "    accuracies['LSTM'] = lstm_accuracy\n",
        "    print(f\"  LSTM Accuracy: {lstm_accuracy:.4f}\")\n",
        "\n",
        "# --- 7. Display Accuracies and Find Best Model ---\n",
        "\n",
        "print(\"\\n--- Model Accuracies ---\")\n",
        "for name, acc in sorted(accuracies.items(), key=lambda item: item[1], reverse=True):\n",
        "    print(f\"{name}: {acc:.4f}\")\n",
        "\n",
        "best_model_name = max(accuracies, key=accuracies.get)\n",
        "best_accuracy = accuracies[best_model_name]\n",
        "print(f\"\\nHighest Accurate Technique: {best_model_name} ({best_accuracy:.4f})\")\n",
        "final_model = trained_models[best_model_name]\n",
        "\n",
        "# --- 8. Apply Highest Accurate Technique on Test Data ---\n",
        "\n",
        "if best_model_name == 'LSTM' and LSTM_AVAILABLE:\n",
        "    # LSTM prediction on padded sequences\n",
        "    y_pred_proba = final_model.predict(X_test_padded)\n",
        "    # Convert probability to binary class (0 or 1)\n",
        "    y_pred_final = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "else:\n",
        "    # ML model prediction on TF-IDF features\n",
        "    y_pred_final = final_model.predict(X_test_tfidf)\n",
        "\n",
        "# --- 9. Output to CSV ---\n",
        "# Create a DataFrame for the output\n",
        "# 0 as fake, 1 as correct (consistent with the mapping)\n",
        "output_df = pd.DataFrame({\n",
        "    'Prediction': y_pred_final\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "output_df.to_csv('fake_news_predictions.csv', index=False)\n",
        "\n",
        "print(\"\\nPrediction complete. Output saved to 'fake_news_predictions.csv'.\")"
      ]
    }
  ]
}